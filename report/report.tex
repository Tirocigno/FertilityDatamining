% !TeX document-id = {140a115a-dcb8-4623-b089-a2a5ac29b468}
%% Direttive TeXworks:
% !TeX root = ./report.tex
% !TEX encoding = UTF-8 Unicode
%% !TEX program = arara
%% !TEX TS-program = arara
% !TeX spellcheck = it-IT

% arara: pdflatex: { synctex: yes, action: batchmode, options: "-halt-on-error -file-line-error-style" }
% arara: pdflatex: { synctex: yes, action: nonstopmode, options: "-halt-on-error -file-line-error-style" }

%% Genera un file report.xmpdata con i dati di titolo e autore per il formato PDF/A %%
\begin{filecontents*}{\jobname.xmpdata}
\Title{Fertility Dataset Analysis}
\Author{Federico Naldini}
\end{filecontents*}

\documentclass[%
  a4paper,            % specifica il formato A4 (default: letter)
  11pt,               % specifica la dimensione del carattere a 12
  oneside,            % serve per impaginare per stampa solo fronte
  notitlepage         % mette il titolo in una pagina separata (solo per article)
]{article}

\usepackage{a4wide}             % consente di avere più spazio nell'A4

%% ORDINE IMPORTANTE INIZIO %%%%%%%%%%%%
\usepackage[T1]{fontenc}        % serve per impostare la codifica di output del font
\usepackage{textcomp}           % serve per fornire supporto ai Text Companion fonts
\usepackage[utf8]{inputenc}     % serve per impostare la codifica di input del font
\usepackage[
  english,            % utilizza l'inglese come lingua secondaria
  italian             % utilizza l'italiano come lingua primaria
]{babel}                        % serve per scrivere Indice, Capitolo, etc in Italiano

\usepackage{lmodern}            % carica una variante Latin Modern prodotto dal GUST
%% ORDINE IMPORTANTE FINE %%%%%%%%%%%%%%

\usepackage{indentfirst}        % serve per avere l'indentazione nel primo paragrafo
\usepackage{setspace}           % serve a fornire comandi di interlinea standard
\usepackage{xcolor}             % serve per la gestione dei colori nel testo
\usepackage{graphicx}           % serve per includere immagini e grafici

\usepackage{float}              % Permette di impostare la posizione assoluta delle immagini

\usepackage{listings} 			%Permette di inserire codice nel documento

\graphicspath{{./fig/}}

\usepackage[%
  strict,             % rende tutti gli warning degli errori
  autostyle,          % imposta lo stile in base al linguaggio specificato in babel
  english=american,   % imposta lo stile per l'inglese
  italian=guillemets  % imposta lo stile per l'italiano
]{csquotes}                     % serve a impostare lo stile delle virgolette

\usepackage{multirow}           % aggiunge la possibilità di raggruppare celle su più righe nelle tabelle

\onehalfspacing%                % Imposta interlinea a 1,5 ed equivale a \linespread{1,5}

\setcounter{secnumdepth}{3}     % Numera fino alla sottosezione nel corpo del testo
\setcounter{tocdepth}{3}        % Numera fino alla sotto-sottosezione nell'indice

\usepackage[%
  depth=3,            % equivale a bookmarksdepth di hyperref
  open=false,         % equivale a bookmarksopen di hyperref
  numbered=true       % equivale a bookmarksnumbered di hyperref
]{bookmark}                     % Gestisce i segnalibri meglio di hyperref
\usepackage{hyperref}           % Gestisce tutte le cose ipertestuali del pdf
\hypersetup{%
  pdfpagemode={UseNone},
  hidelinks,          % nasconde i collegamenti (non vengono quadrettati)
  hypertexnames=false,
  linktoc=all,        % inserisce i link nell'indice
  unicode=true,       % only Latin characters in Acrobat’s bookmarks
  pdftoolbar=false,   % show Acrobat’s toolbar?
  pdfmenubar=false,   % show Acrobat’s menu?
  plainpages=false,
  breaklinks,
  pdfstartview={Fit},
  pdfauthor={Federico Naldini},
  pdfcreator={Federico Naldini},
  pdftitle={Fertility Dataset Analysis},
  pdflang={it}
}
%\usepackage[a-1b]{pdfx}
\usepackage[%
  english,italian,    % definizione delle lingue da usare
  nameinlink          % inserisce i link nei riferimenti
]{cleveref}                     % permette di usare riferimenti migliori dei \ref e dei varioref

\title{\LARGE{\textbf{Fertility Dataset Analysis}}}

\author{%
  Federico~Naldini
}

\date{%
  \small{Data Mining}\\%
  \small{Anno accademico 2018--2019}
}

\begin{document}

  \maketitle
  \clearpage
  \tableofcontents
  \clearpage

  \section{Introduzione}
  In questa sezione verranno presentati brevemente il dataset su cui è stato svolto il lavoro e le tecniche utilizzate per riuscire a dedurre conoscenza dai dati in questione.
  \subsection{Descrizione del Dataset}
  Per produrre il mio elaborato, ho scelto di condurre le operazioni di studio e mining dei dati sul dataset chiamato \textit{Fertility Data Set}.
  Questo dataset contiene i risultati degli esami di fertilità, effettuati su campioni di seme secondo i criteri dell'Organizzazione Mondiale della Sanità, di 100 uomini; il risultato di questi esami può essere di due tipologie, Normale oppure Alterato, che indica un potenziale problema di sterilità nel paziente. Questi risultati sono correlati all'interno del dataset a dati di natura socio-demografica, ambientale e abitudinaria dei soggetti analizzati. 
  Il problema delineato è dunque affrontabile come un quesito di  classificazione binaria: si deve infatti poter costruire un modello che, dati certi parametri per gli attributi presi in causa, permetta di prevedere un potenziale problema di fertilità o meno.
  Come detto sopra, gli attributi presi in considerazione sono di natura molto diversa tra loro e non tutti di banale correlazione per un non esperto del dominio al problema della fertilità, di seguito vengono riportati gli attributi presenti nel dataset:
  \begin{itemize}
  	\item \texttt{Season}:Attributo che rappresenta la stagione in cui è stato svolto l'esame, ha quattro valori possibili, corrispondenti alle stagioni astronomiche dell'anno solare(-1 Primavera, -0.33 Estate, 0.33 Autunno, 1 Inverno)
  	
  	\item \texttt{Age}:Attributo che rappresenta l'età dei partecipanti al test, ha dominio compreso tra 0.5(corrispondente a 18 anni) e 1(36 anni).
  	
  	\item \texttt{Childish-disease}:Attributo binario(rappresentato coi valori 0 e 1) che rappresenta la presenza o meno di patologie clinicamente rilevanti(\textit{Varicella, Orecchioni, Morbillo..}) contratte dal paziente durante l'infanzia.
  
  	\item \texttt{Trauma}:Attributo binario(rappresentato coi valori 0 e 1) che rappresenta la presenza o meno di traumi/incidenti rilevanti nella storia clinica del paziente.	
  	
  	\item \texttt{Surgical Intervantion}:Attributo binario(rappresentato coi valori 0 e 1) che rappresenta la presenza o meno di interventi chirurgici nella storia clinica del paziente.
  	
  	\item \texttt{Fever}:Attributo per identificare la presenza o meno di febbri particolarmente alte in relazione ai tre mesi precedenti al test(-1), in un tempo antecedente ai tre mesi(0) oppure mai(1)
  	
  	\item \texttt{Alchoolic}:Rappresenta la frequenza del consumo di alcool, diviso in cinque categorie(corrispondenti a 5 valori tra 0.2(Più volte al giorno), 0.4(Una volta al giorno), 0.6(Più volte alla settimana), 0.8(una volta a settimana), 1(molto raramente o mai)).
  	
  	\item \texttt{Smoking}:Le abitudini del soggetto rispetto al fumo: fumatore abituale(-1), sporadico(0), non fumatore(1)
  	
  	\item \texttt{Sitting}:Quantifica le ore trascorse sedute al giorno dal soggetto in un range compreso tra una (valore corrispondente 0.06) e 16 (valore corrispondente 1).
  	
  \end{itemize} 

  \subsection{Tecniche utilizzate}
  Dato che il dataset presentava un problema di classificazione binaria, diversi classificatori e tecniche potevano essere utilizzate e i loro risultati confrontati tra di loro, al fine di individuare quali fossero i modelli più solidi.\\
  Per cominciare nella fase di \texttt{preprocessing} ho utilizzato \textit{Istogrammi} e \textit{Grafici di distribuzione}, successivamente per la classificazione vera e propria, ho scelto un classificatore per ciascuna delle tipologie di classificatori viste a lezione, ovvero \texttt{J-48} per \textit{Decision Tree},\texttt{JRIP} per \textit{Rule-Based Classifiers}, \texttt{IBK} per \textit{Lazy Classifiers}, \texttt{Naive Bayes} per i \textit{Classificatori Bayesiani}.
  Infine per quanto riguarda i multi-classificatori, ho scelto di usare \texttt{Adaboost} per la tipologia di \textit{Boosting}, \texttt{Bagging} per l'omonima famiglia e infine \texttt{Cost-Sensitive Classifier} per ragioni che verranno spiegate nella sezione 2.
  \section{Analisi dei dati}
  In questa sezione verrà riportato lo studio effettuato sul dataset, ogni sottosezione tratterà di uno specifico classificatore, dei suoi risultati e degli esperimenti fatti per migliorarne il modello.
  Prima di partire con i vari dati, occorre però stabilire i criteri di misura delle performance dei vari classificatori: a tale scopo ho tenuto conto in primo luogo della \texttt{Confusion Matrix} prodotta da ogni modello, successivamente dei valori di \texttt{Precision} e \texttt{Recall} per le classi in gioco e infine del valore della \texttt{ROC}.
  Come modalità di test ho scelto di applicare in ogni situazione la \texttt{K-Fold Cross-Validation} piuttosto che lo splitting statico dei dati in \texttt{Training} e \texttt{Test Set}, la motivazione dietro a questa scelta è l'esiguo numero di dati presenti nel dataset a cui si presta meglio una modalità come il \texttt{K-Fold Cross-Validation}, in quanto pensata appositamente per dataset di piccole dimensioni.
  \subsection{Preprocessing}
  Durante la fase di preprocessing, ho studiato la composizione dei dati e pensato quali potessero essere le principali tecniche da applicare.
  La prima cosa che mi è saltata all'occhio all'apertura del dataset è sicuramente la sua sbilanciatezza nelle classi di output: su 100 pazienti in esame, solo 12 risultano compromessi, come mostrato nella figura 1
  
  \begin{figure}[H]
  	\includegraphics{IstogrammaClassi.png}
  	\caption{Istogramma delle classi in gioco, la colonna blu rappresenta le diagnosi di fertilità normale, quella rossa gli esami che evidenziano potenziali problematiche}
  \end{figure}

Questo disequilibrio tra le classi mette in difficoltà i modelli più semplici, costringendomi così a ricercare e mettere alla prova diverse configurazioni parametriche nei modelli da me utilizzati, al fine di ottenere risultati validi.
Parlando poi degli attributi presenti nel dataset, non ho dovuto fare particolari operazioni di elaborazione o pulizia: tutti i dati si presentavano infatti come composti da attributi numerici,discreti e semi-normalizzati(il \texttt{Range} per ogni attributo variava massimo tra -1 e 1); di conseguenza non ho effettuato operazioni permanenti di \texttt{Discretizzazione, Trasformazione, Selezione di Attributi} o \texttt{Replace dei valori mancanti}, unica trasformazione permanente applicata ai dati è stata la \texttt{Normalizzazione} per rendere i range dei vari attributi omogenei tra di loro.
Non essendo i classificatori applicati particolarmente influenzati dalla \texttt{Normalizzazione} dei dati, fatta eccezione per \texttt{IBK} che richiede tale processo come requisito per il suo funzionamento ottimo, ho utilizzato la versione normalizzata dei dati per la maggior parte dei classificatori, realizzando ogni tanto qualche prova con la loro versione non normalizzata per individuare eventuali differenze.\\
Parlando poi degli attributi, in totale 10, ho condotto un'analisi sugli istogrammi ottenuti, valutando per ogni attributo il rapporto tra i valori assunti e la classe delle varie istanze considerate.
Nella procedura di analisi ho scelto di applicare il filtro \texttt{Discretize} per raggruppare i dati in tanti intervalli quanti i valori distinti assumibili dall'attributo in questione,così da avere istogrammi più chiari e facilmente interpretabili.

\begin{itemize}
	\item \texttt{Season}:Discretizzando l'attributo su quattro valori corrispondenti alle stagioni, si verifica che per l'autunno sono presenti solo quattro record, inoltre la frequenza di esami con esito problematico tendono ad aumentare leggermente durante estate e inverno, questo potrebbe essere dovuto alle condizioni di forte caldo o gelo tipiche di quelle stagioni.
	\begin{figure}[H]
		\includegraphics[scale=0.9]{IstogrammaStagioni.png}
		\caption{Istogramma relativo alla distribuzione del dataset sull'attributo \texttt{season}, le quattro colonne rappresentano le stagioni nell'ordine: primavera, estate, autunno, inverno}
	\end{figure}
	
	\item \texttt{Age}:Discretizzando l'attributo su 18 valori, si verifica che la distribuzione non è omogenea, ma tendono a essere molto più frequenti i pazienti con età più vicina a 18 anni che  36; particolare attenzione merita però la distribuzione dei pazienti con esame di fertilità problematico: i casi di infertilità tendono infatti a concentrarsi dopo i 24 anni, con picco proprio su tale anno, probabilmente dovuto a una frequenza maggiore di tale valore.
	
		\begin{figure}[H]
		\includegraphics[scale=0.9]{IstogrammaEta.png}
		\caption{Istogramma relativo alla distribuzione del dataset sull'attributo \texttt{age}, le colonne rappresentano ciascuna un'età compresa tra 18 e 36}
	\end{figure}
	
	\item \texttt{Childish-disease}:I casi di fertilità e infertilità risultano abbastanza bilanciati sulle due colonne dell'istogramma, mentre gli individui affetti da problematiche durante l'infanzia sono molti meno rispetto agli altri; si può supporre quindi che questo attributo non sia particolarmente rilevante ai fini di una diagnosi della fertilità. 
	
	\begin{figure}[H]
		\includegraphics[scale=0.9]{IstogrammaMalattieInfantili.png}
		\caption{Istogramma relativo alla distribuzione del dataset sull'attributo \texttt{childish-desease}, le due colonne rappresentano in ordine i soggetti che hanno contratto malattie importanti da bambini e quelli che non le hanno avute}
	\end{figure}
	
	\item \texttt{Trauma}:Considerando una distribuzione abbastanza bilanciata rispetto all'attributo, si può notare che la maggior parte degli esami di fertilità problematici si concentra in corrispondenza di un trauma nella storia clinica(figura 4)	
	
		\begin{figure}[H]
		\includegraphics[scale=0.9]{IstogrammaTrauma.png}
		\caption{Istogramma relativo alla distribuzione del dataset sull'attributo \texttt{trauma}, le due colonne rappresentano in ordine i soggetti che hanno subito traumi da bambini e quelli che non li hanno subiti}
	\end{figure}
	
	\item \texttt{Surgical Intervantion}:L'istogramma risulta bilanciato rispetto sia all'attributo sia alla classe, quindi si può supporre che la presenza di un intervento chirurgico non sia strettamente correlata alla fertilità di un individuo.
	
	\begin{figure}[H]
		\includegraphics[scale=0.9]{IstogrammaInterventoChirurgico.png}
		\caption{Istogramma relativo alla distribuzione del dataset sull'attributo \texttt{surgical-intervention}, le due colonne rappresentano in ordine i soggetti che hanno subito interventi chirurgici da e quelli mai operati}
	\end{figure}
	
	\item \texttt{Fever}:I dati risultano sbilanciati su questo attributo, con una maggiore frequenza per coloro che hanno avuto un episodio di febbre alta a oltre tre mesi di distanza dall'esame; tale squilibrio può essere considerato normale, visto il criterio di suddivisione applicato all'attributo(febbre registrata entro tre mesi dalla data, oltre tre mesi, mai registrata) risulta naturale che il secondo intervallo(a oltre tre mesi di distanza dall'esame) risulta molto più amplio degli altri due e di conseguenza avrà una frequenza maggiore nei dati.
	Considerato ciò, la distribuzione degli esami problematici risulta bilanciata tra le colonne dell'istogramma rispetto al numero di elementi per ogni colonna. 
	
	\begin{figure}[H]
		\includegraphics[scale=0.9]{IstogrammaFebbre.png}
		\caption{Istogramma relativo alla distribuzione sul dataset dell'attributo \texttt{fever}, le tre colonne rappresentano in ordine i soggetti che hanno avuto febbri alte nei tre mesi antecedenti all'esame, oltre tali mesi e infine mai}
	\end{figure}
	
	\item \texttt{Alchoolic}:I dati risultano sbilanciati rispetto a questo attributo con una concentrazione maggiore verso i valori che indicano un raro consumo di alcool. Tra coloro che consumano alcool una o più volte a settimana e quelli che invece si dichiarano astemi, il tasso di esami problematici tende a crescere per la prima categoria rispetto alla seconda, mentre le altre categorie contengono un numero praticamente insignificante di dati, limitando così la loro incidenza.
	
		\begin{figure}[H]
		\includegraphics[scale=0.9]{IstogrammaAlcool.png}
		\caption{Istogramma relativo alla distribuzione sul dataset dell'attributo \texttt{Alchoolic}, le colonne rappresentano in ordine i soggetti che consumano alcool più volte al giorno, una volta al giorno, più volte a settimana, una volta a settimana, mai}
	\end{figure}
	
	\item \texttt{Smoking}:Rispetto alle abitudini da fumatore del soggetto, i potenziali problemi di sterilità risultano più frequenti negli individui fumatori, occasionali o meno, rispetto ai non fumatori.
	
		\begin{figure}[H]
		\includegraphics[scale=0.9]{IstogrammaFumo.png}
		\caption{Istogramma relativo alla distribuzione sul dataset dell'attributo \texttt{smoking}, le colonne rappresentano in ordine i non fumatori, gli occasionali, coloro che fumano almeno una volta al giorno}
	\end{figure}
	
	
	\item \texttt{Sitting}:Dal corrispondente istogramma(figura 10), si deduce che il dataset contenga più dati aventi valori nel range 1-8 rispetto a 8-16; all'interno del primo range gli esami problematici tendono a concentrarsi verso i valori più alti dell'intervallo, si può quindi dedurre che il tempo trascorso seduti al giorno possa influire sui problemi di fertilità
	
		\begin{figure}[H]
		\includegraphics[scale=0.9]{IstogrammaSeduto.png}
		\caption{Istogramma relativo alla distribuzione sul dataset dell'attributo \texttt{sitting}, le colonne rappresentano in ordine le ore trascorse seduto al giorno dal soggetto, da 1 a 16 compresi}
	\end{figure}
	
\end{itemize} 

Dopo aver analizzato i singoli attributi, ho proseguito osservando i grafici di dispersione tra i vari attributi, senza però notare particolari relazioni tra le distribuzioni dei vari dati.

  
  
  \subsection{Decision Tree}
  La prima tecnica di classificazione che ho testato è stata il \texttt{Decision Tree}, in particolare ho scelto di usare l'implementazione \texttt{J-48}, che realizza un albero binario a possono essere applicate tecniche di \texttt{Post pruning} per ridurre le dimensioni dell'albero e l'errore commesso dal classificatore.\\
  In primo luogo ho provato a generare un modello applicando i parametri standard impostati dall'editor Weka, ottenendo così i risultati riportati in figura 11
  
  \begin{figure}[H]
  	\includegraphics[scale=0.5]{J48DefaultTree.png}
  	\caption{Output della classificazione con J48 Tree Pruned}
  \end{figure}

Com'è possibile notare dai dati in figura, il classificatore costruisce un modello poco valido: per quanto l'accuratezza totale, \texttt{Precision}, \texttt{Recall} per la classe \texttt{N} abbiano valori piuttosto alti, i corrispondenti per \texttt{O} risultano tendenti allo 0, inoltre il valore di \texttt{ROC}, indicatore principale della bontà di un modello di classificazione, risulta terribilmente basso. Osservando la \texttt{Confusion Matrix} e la struttura dell'albero costruito, è piuttosto chiaro che il motivo di valori tanto bassi: l'albero infatti è costruito da un'unica foglia i cui valori sono assegnati alla classe N, causando così la situazione sopradescritta.\\
Ovviamente questo modello non risultava di una qualità soddisfacente, la causa di questo era dovuta sicuramente al \texttt{post pruning}, responsabile di ridurre l'albero di classificazione a singola foglia, tale risultato ho supposto fosse dovuto allo sbilanciamento nella frequenza delle classi.
Per porre rimedio a questa cosa, ho provato a aumentare e diminuire il parametro \texttt{confidenceFactor}, responsabile di accentuare o smussare le operazioni di pruning; anche però variando questo parametro i risultati ottenuti non sono stati notevolmente differenti dalla versione sopradescritta, l'albero prodotto risultava sempre composto da una sola foglia.
La situazione è decisamente migliorata nel momento in cui ho provato a disattivare il pruning: questa scelta ha finalmente prodotto un risultato notevolmente differente dai precedenti, nella figura 12  vengono riportati l'albero di classificazione e i risultati ottenuti dal modello così costruito

\begin{figure}[H]
	\includegraphics[scale=0.6]{J48UnprunedTree.png}
	\includegraphics[scale=0.5]{J48UnprunedTreeStat.png}
	\caption{Albero di classificazione e output ottenuto con J48 Unpruned}
\end{figure}
Com'è possibile dedurre osservando la \texttt{Confusion Matrix} e \texttt{ROC}, il risultato del classificatore è sicuramente migliore rispetto alla sua versione Pruned, tuttavia il risultato rimane ancora abbastanza insoddisfacente, soprattutto per le istanze della classe O.
Facendo vari esperimenti con la versione unpruned di J48, ho notato che abbassando il numero minimo di elementi per foglia a 1, il valore di \texttt{Recall} per la classe O e di \texttt{True Positive} si alza ma il valore di \texttt{ROC} e \texttt{Precision} si abbassano.
Le considerazioni emerse in fondo sono le seguenti: sicuramente il classificatore J48 non garantisce risultati ottimali sopra questo dataset, soprattutto a causa della grande sbilanciatezza tra i dati, tuttavia disattivando il post pruning e abbassando il numero minimo di elementi per foglia a 1, si può classificare correttamente poco meno della metà degli elementi appartenente a O, classe più difficile da individuare ma allo stesso tempo più rilevante rispetto al dominio dei dati del sistema.
  
  \subsection{Classificatori Bayesiani}
  Per tentare un approccio diverso dai precedenti, ho provato a costruire un modello basato sui classificatori bayesiani, approccio che ignora le relazioni tra gli attributi in favore della frequenza di certi valori rispetto alle classi in gioco.
  Il classificatore specifico scelto per il dataset è stato \texttt{NaiveBayes} nella sua implementazione fornita da Weka; costruendo il modello utilizzando i parametri standard impostati da Weka, ho ottenuto i seguenti risultati, mostrati in figura 13:
  
  \begin{figure}[H]
  	\includegraphics[scale=0.6]{NaiveBayesOutput.png}
  	\caption{Output del classificatore Naive Bayes}
  \end{figure}

Analizzando i risultati di questo classificatore, si possono fare diverse considerazioni: partendo dall'osservazione della \texttt{Confusion Matrix} è possibile vedere come tutti i dati vengano assegnati alla classe "N", mentre "O" rimane vuota, ciò è ulteriormente confermato dai valori di \texttt{Precision} e \texttt{Recall} per la classe "O", che risultano rispettivamente non calcolata e 0, infine osservando \texttt{R.O.C} si ha la conferma definitiva che il modello costruito sia decisamente inefficiente e poco performante.
Le ragioni dietro alla poca efficienza del modello Bayesiano per questo problema possono essere ricondotte alla mancanza dei valori di distribuzione delle probabilità reali per le classi e alla potenziale mancanza di indipendenza statistica tra attributi; questi fattori, combinati allo sbilanciamento dei dati nel dataset, da cui vengono estratte le distribuzioni di probabilità necessarie al classificatore in mancanza di quelle reali, rendono inefficace il modello bayesiano su questo dataset. 

  \subsection{Classificatori Lazy}
  Ultima famiglia da me utilizzata è stata quella dei classificatori \texttt{Instance-Based} o Lazy che dir si voglia, la particolarità di queste tecniche è la totale assenza di modello, sostituito da procedure di natura induttiva.
  Tra tutti i classificatori disponibili in questa famiglia, ho scelto di utilizzare \texttt{IBK}, implementazione in Weka dell'algoritmo KNN; per questo classificatore è possibile impostare diversi parametri come il numero di vicini da considerare e la metrica da utilizzare nel calcolo della distanza.
  Applicando i parametri default di Weka, ovvero un vicino e distanza euclidea, si ottengono i risultati descritti in figura 14
  
  \begin{figure}[H]
  	\includegraphics[scale=0.6]{IB1Output.png}
  	\caption{Output del classificatore IBK con K=1 e distanza Euclidea}
  \end{figure}

I risultati ottenuti da questo modello risultano non particolarmente buoni, tuttavia i valori di \texttt{Confusion Matrix}, \texttt{R.O.C}, \texttt{Precision} e \texttt{Recall} per la classe "0" sono comunque discreti rispetto a quelli ottenuti nei tentativi precedenti, lasciando intendere che il modello possa essere migliorato utilizzando valori differenti per i parametri sopradescritti.\\
Mantenendo la distanza euclidea come metrica, ho provato a variare il valore di K tra i numeri dispari compresi tra 3 e 11, ottenendo con K = 5 la massimissazione del valore di \texttt{R.O.C}(figura 15) mentre per K = 3 i massimi valori di \texttt{Precision} e \texttt{Recall} della classe "O"(figura 16).

\begin{figure}[H]
	\includegraphics[scale=0.6]{IB5Output.png}
	\caption{Output del classificatore IBK con K=5 e distanza Euclidea}
\end{figure}

\begin{figure}[H]
	\includegraphics[scale=0.6]{IB3Output.png}
	\caption{Output del classificatore IBK con K=3 e distanza Euclidea}
\end{figure}

Cambiando il numero dei vicini da considerare i risultati cambiano leggermente, tuttavia il modello arranca ancora nel riconoscimento degli elementi della classe "O", le ragioni di questo comportamento sono sicuramente non solo lo sbilanciamento nelle classi di output ma anche la mancanza di una separazione netta tra i dati a livello di valori degli attributi.\\
Non avendo ottenuto risultati soddisfacenti alterando il numero dei vicini, ho provato a concentrarmi sul cambio di metrica per misurare la distanza tra punti, ovvero i dati nello spazio: tra tutte le metriche messe a disposizione da Weka, la distanza di Chebyshev, che misura la distanza tra due vettori come la maggiore tra le differenze dei singoli attributi, ha ottenuto i risultati migliori migliorando i valori ottenuti con la distanza euclidea sia per K = 3(figura 17) che per K = 5(figura 18).

\begin{figure}[H]
	\includegraphics[scale=0.6]{IB3Chernobil.png}
	\caption{Output del classificatore IBK con K=3 e distanza di Chebyshev}
\end{figure} 

\begin{figure}[H]
	\includegraphics[scale=0.6]{IB5Chernobil.png}
	\caption{Output del classificatore IBK con K=5 e distanza di Chebyshev}
\end{figure} 

Il miglioramento dovuto al cambio di metrica può dipendere dal fatto che mentre la distanza euclidea, basata su tutte le componenti del vettore, ergo gli attributi, produca una vicinanza significativa tra elementi di classe "N" e "O" portando così a errori di classificazione, la distanza di Chebyshev riesca a separare meglio i dati delle due classi considerando solo l'attributo per cui la distanza è massima, quindi aumentando la distanza tra i punti.
  
  \subsection{Multi-Classificatori}
Non avendo trovato un modello particolarmente efficace con i tentativi fatti con i classificatori precedentemente descritti, ho deciso di cambiare approccio e di provare i modelli a multi-classificatori, da molti descritti come particolarmente efficaci per i problemi in cui i classificatori semplici  facevano fatica a raggiungere performance accettabili.
Tra le varie possibilità messe a disposizione da Weka, ho scelto di utilizzare due diversi algoritmi: \texttt{Cost-Sensitive Classifier}, modello che permette di gestire dataset sbilanciati in partenza per distribuzioni delle classi e \texttt{Adaboost}, classificatore appartenente alla famiglia delle tecniche di \texttt{Boosting}
  \subsubsection{Approccio Cost-Sensitive}
  I Classificatori \texttt{Cost-Sensitive} sono uno degli strumenti più efficaci per gestire dataset non bilanciati, consentono infatti di poter attribuire un peso alle istanze sbagliate delle varie classi in gioco, eseguendo così una procedura di \texttt{Model Tuning}.\\
  L'implementazione messa a disposizione da Weka permette di selezionare un classificatore su cui costruire il modello, i cui parametri possono essere settati a piacere, e una matrice di costo di dimensione N X N(dove N è il numero delle classi in gioco), dove è possibile assegnare una penalità differente alle varie istanze classificate per ogni classe.
  Il primo classificatore che ho testato è stato \texttt{J-48} specificando vari valori per la matrice di costo(che di volta in volta accrescevano la penalità dovuta all'errata classificazione di elementi di classe "N" come elementi di classe "O"): al crescere del peso aumentavano sia il numero di istanze classificate correttamente come classe "O", sia quelle appartenenti alla classe "O" assegnate a "N".
  Questa tendenza è assolutamente in linea con il principio di funzionamento dei classificatori \texttt{Cost-Based}: un buon equilibrio si può trovare attorno a una penalità di valore circa 20, che garantisce \texttt{R.O.C} massima(figura 19).
  
  \begin{figure}[H]
  	\includegraphics[scale=0.6]{CostBased20J48.png}
  	\caption{Output del classificatore Cost based, basato su un J48 unpruned, con penalità per errori su classe "O" pari a 20 }
  \end{figure} 

Cambiando classificatore di base in \texttt{Naive Bayes}, i risultati migliorano rispetto alla versione normale del classificatore di Bayes, tuttavia le performance rimangono inferiori rispetto al modello costruito con J48; probabilmente l'approccio \texttt{Cost-Based} migliora l'efficacia del modello \texttt{NaiveBayes}, tuttavia le problematiche espresse nella sezione 2.3 sono talmente importanti da non rendere il classificatore valido nemmeno in questa casistica.\\
Per ultimo ho lasciato \texttt{IBK}, classificatore con cui avevo ottenuto i migliori risultati nelle sezioni precedenti. Applicando i modelli descritti nella sezione 2.4, ho ottenuto alcuni risultati decisamente validi: il miglior risultato in assoluto è stato ottenuto utilizzando K = 5, distanza euclidea e penalità per i record mal classificati di "O" uguale a 5(figura 20). 

\begin{figure}[H]
	\includegraphics[scale=0.6]{KKK.png}
	\caption{Output del classificatore Cost based, basato su IBK con K = 5, con penalità per errori su classe "O" pari a 5.0}
\end{figure} 

Osservando la \texttt{Confusion Matrix}, si può notare che questo classificatore abbia il più alto numero di veri positivi mai classificati per la classe "O", a discapito però di un elevato numero di istanze di "N" classificate come elementi di "O"; nonostante questo i valori di \texttt{R.O.C} e delle altre metriche considerate risultano in media superiori a qualunque altro modello testato. 
I buoni risultati ottenuti da questo classificatori sono dovuti all'applicazione a un modello già superiore agli altri in termini di performance sul dataset, ovvero IBK, di un insieme di tecniche per ridurre l'impatto della sbilanciatezza dei dati nelle classi, creando così un modello che nel complesso risulta abbastanza valido e funzionale.

  \subsubsection{Approccio Boosting}
Ultimo approccio in assoluto che ho tentato è stato il boosting, processo che si basa sulla costruzione di più classificatori attribuendo ogni volta un peso maggiore agli elementi mal classificati al passo precedente.
Come per i classificatori cost-based, anche qui è possibile specificare un modello di base per costruire la classificazione e sempre analogamente ho testato tutti e tre i classificatori base impiegati ai passi precedenti(\texttt{NaiveBayes, J48} e \texttt{IBK})  
  \section{Conclusioni}
  
\end{document}
